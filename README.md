# Voice Assistant

A cross-platform voice assistant with persistent memory that lets you have natural conversations with your computer using open-source libraries.

## Features

- ğŸ¤ **Cross-platform audio** - Works on Windows, Mac, and Linux
- ğŸ—£ï¸ **Speech-to-Text** - faster-whisper (4x faster than standard Whisper)
- ğŸ¤– **Local LLM** - Powered by Ollama (llama2, llama3, etc.)
- ğŸ”Š **Text-to-Speech** - Natural Microsoft Edge voices via edge-tts
- âš¡ **Barge-in** - Interrupt the assistant mid-speech by talking
- ğŸ¯ **Voice Activity Detection** - Automatic speech start/stop detection
- ğŸ’¾ **Persistent Memory** - PostgreSQL + pgvector for long-term memory
- ğŸ” **Semantic Search** - Find past conversations by meaning

## Memory Architecture

The assistant uses a multi-layer memory system:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEMORY LAYERS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: Recent Messages (Short-term)                       â”‚
â”‚   â†’ Last 20 messages in current session                     â”‚
â”‚   â†’ Full context for immediate conversation                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: Conversation Summaries (Medium-term)               â”‚
â”‚   â†’ Auto-generated when context gets too long               â”‚
â”‚   â†’ Condensed history with key topics                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: Vector Embeddings (Long-term)                      â”‚
â”‚   â†’ Semantic search over all past conversations             â”‚
â”‚   â†’ Powered by pgvector + sentence-transformers             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: User Profile                                       â”‚
â”‚   â†’ Learned preferences (name, interests, etc.)             â”‚
â”‚   â†’ Persists across all sessions                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

1. **Python 3.10+**
2. **Ollama** - Install from [ollama.ai](https://ollama.ai) and run:
   ```bash
   ollama serve
   ollama pull llama2
   ```
3. **PostgreSQL with pgvector** (optional, for persistent memory):
   ```bash
   # Ubuntu/Debian
   sudo apt install postgresql postgresql-contrib
   
   # Install pgvector extension
   # See: https://github.com/pgvector/pgvector
   ```

### Installation

```bash
# Clone the repository
git clone https://github.com/DobosP/speaker.git
cd speaker

# Install dependencies
pip install -r requirements.txt

# (Optional) Setup database for persistent memory
python setup_database.py --create-db
```

### Usage

```bash
# Run the assistant (with memory)
python main.py

# Run without persistent memory
python main.py --no-memory

# Start a fresh session
python main.py --new-session

# Continue a specific session
python main.py --session-id abc123

# Use custom database
python main.py --db-url "postgresql://user:pass@host/db"

# List available audio devices
python main.py --list-devices

# Use specific input device
python main.py --input-device 2

# Use different LLM model
python main.py --llm-model llama3

# Use different STT model
python main.py --stt-model small

# Use different TTS voice
python main.py --tts-voice en-GB
```

### Commands

- **Say anything** - The assistant will respond
- **Say "stop" or "quit"** - Exit the application
- **Speak while assistant is talking** - Interrupt (barge-in)
- **Reference past conversations** - "What did I tell you last time about..."

## Configuration

Edit `config.json` to customize:

```json
{
  "vad_threshold": 0.005,
  "silence_duration": 1.5,
  "sample_rate": 16000,
  "input_device": null,
  "output_device": null,
  "llm_model": "llama2",
  "stt_model": "base",
  "tts_voice": "en-US"
}
```

### Environment Variables

```bash
# Database connection (optional)
export DATABASE_URL="postgresql://localhost/voice_assistant"
```

### STT Models (faster-whisper)

| Model | Speed | Quality | VRAM |
|-------|-------|---------|------|
| tiny | Fastest | Good | ~1GB |
| base | Fast | Better | ~1GB |
| small | Medium | Great | ~2GB |
| medium | Slow | Excellent | ~5GB |
| large-v3 | Slowest | Best | ~10GB |

### TTS Voices (edge-tts)

| Voice | Description |
|-------|-------------|
| en-US | US English (Aria, female) |
| en-US-male | US English (Guy, male) |
| en-GB | British English (Sonia, female) |
| en-AU | Australian English (Natasha, female) |

### VAD Threshold Tuning

| Value | Use Case |
|-------|----------|
| 0.001 | Very quiet environment, sensitive mic |
| 0.005 | Normal room, typical mic |
| 0.01  | Noisy environment |
| 0.02+ | Very noisy or if getting false triggers |

## Project Structure

```
voice-assistant/
â”œâ”€â”€ main.py              # Main application entry point
â”œâ”€â”€ config.json          # Configuration file
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ setup_database.py    # Database setup script
â”œâ”€â”€ run_tests.py         # Test runner
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio.py         # Cross-platform audio recording/playback
â”‚   â”œâ”€â”€ stt.py           # Speech-to-text (faster-whisper)
â”‚   â”œâ”€â”€ llm.py           # LLM integration (Ollama)
â”‚   â””â”€â”€ memory.py        # Multi-layer memory system
â””â”€â”€ tests/
    â”œâ”€â”€ test_audio.py    # Audio module tests
    â”œâ”€â”€ test_stt.py      # STT module tests
    â”œâ”€â”€ test_llm.py      # LLM module tests
    â””â”€â”€ test_integration.py  # Integration tests
```

## Database Setup

For persistent memory across sessions:

```bash
# Create database and tables
python setup_database.py --create-db --db-name voice_assistant

# Verify setup
python setup_database.py --verify-only

# Custom host/user
python setup_database.py --create-db --host localhost --user myuser --password mypass
```

### PostgreSQL + pgvector Installation

```bash
# Ubuntu/Debian
sudo apt install postgresql postgresql-contrib

# Install pgvector (required for semantic search)
cd /tmp
git clone https://github.com/pgvector/pgvector.git
cd pgvector
make
sudo make install

# Enable extension in your database
psql -d voice_assistant -c "CREATE EXTENSION vector;"
```

## Running Tests

```bash
# Run all tests
python run_tests.py

# Run specific test suite
python run_tests.py --audio    # Audio tests only
python run_tests.py --stt      # STT tests only
python run_tests.py --quick    # Fast tests (skip model loading)
```

## Troubleshooting

### No audio input detected
- Run `python main.py --list-devices` to see available devices
- Try specifying a device: `python main.py --input-device <number>`

### Barge-in not working
- Lower the VAD threshold in `config.json`
- Speak louder or move closer to the microphone

### Whisper hallucinating (transcribing silence)
- Increase the VAD threshold in `config.json`
- Check for background noise

### LLM not responding
- Make sure Ollama is running: `ollama serve`
- Check the model is downloaded: `ollama list`

### Database connection failed
- Check PostgreSQL is running: `sudo systemctl status postgresql`
- Verify connection URL: `psql "postgresql://localhost/voice_assistant"`
- Run without memory: `python main.py --no-memory`

## License

MIT License - feel free to use and modify.

## Contributing

Contributions welcome! Please open an issue or PR.
